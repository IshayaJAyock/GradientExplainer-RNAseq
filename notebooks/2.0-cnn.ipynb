{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 2D CNN on GTEx V8\n",
    "\n",
    "This file is part of the Verifying explainability of a deep learning tissue classifier trained on RNA-seq data project.\n",
    "\n",
    "Verifying explainability of a deep learning tissue classifier trained on RNA-seq data project is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "\n",
    "Verifying explainability of a deep learning tissue classifier trained on RNA-seq data project is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with the Verifying explainability of a deep learning tissue classifier trained on RNA-seq data project.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "> Investigation into 2D CNN with different imbalanced and balanced datasets from GTEx v8\n",
    "\n",
    "### Input files:\n",
    "1. *gtex_filtered_tmm_intersect_{data_type}.pkl*\n",
    "2. *gtex_filtered_tmm_intersect_test.pkl*\n",
    "\n",
    "\n",
    "### Output files:\n",
    "1. *{data_type}_model_topology.json*\n",
    "2. *{data_type}_model_weights.hdf5*\n",
    " \n",
    "### Table of contents:\n",
    "1. [Import Modules](#1.-Import-Modules)  \n",
    "2. [Set static paths](#2.-Set-static-paths)  \n",
    "3. [Load files](#3.-Load-files)  \n",
    "    3.1 [Load training data](#3.1-Load-training-data)  \n",
    "4. [Process data](#4.-Process-data)  \n",
    "    4.1 [Split X and y](#4.1-Split-X-and-y)  \n",
    "    4.2 [Transform data](#4.2-Transform-data)  \n",
    "    4.3 [Add labels](#4.3-Add-labels)\n",
    "5. [Train model](#5.-Train-model)  \n",
    "    5.1 [Fit model](#5.1-Fit-model)  \n",
    "    5.2 [Save model](#5.2-Save-model)  \n",
    "6. [Test model](#6.-Test-model)  \n",
    "    6.1 [Load GTEx v8 data](#6.1-Load-GTEx-v8-data)  \n",
    "    6.2 [Prepare data](#6.2-Prepare-data)  \n",
    "    6.3 [Load model](#6.3-Load-model)  \n",
    "    6.4 [Run inference](#6.4-Run-inference)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_path = '../src'\n",
    "os.chdir(util_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from modelling.cnn import convert_2d, convert_onehot, keras_cnn, log_transform\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single GPU to use \n",
    "# Skip this part if you're parallelising or only have 1 GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"; \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set static paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"imbalanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../data/processed/\"\n",
    "model_dir = \"../models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key = f\"gtex_filtered_tmm_intersect_{data_type}.pkl\"\n",
    "gtex_tmm = pickle.load(open(os.path.join(input_dir, key), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gtex_tmm.drop(\"type\", axis=1)\n",
    "y_train = gtex_tmm[\"type\"]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = log_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_converted = convert_2d(X_train)\n",
    "y_train_converted = convert_onehot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cnn(X_train_converted, y_train_converted)\n",
    "print(\"Model Initiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model beautifully\n",
    "model.fit(\n",
    "    X_train_converted, \n",
    "    y_train_converted, \n",
    "    batch_size=128, \n",
    "    epochs=11,\n",
    "    verbose=1,\n",
    "    validation_split=0.1, \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model JSON and weights\n",
    "model_json = model.to_json()\n",
    "with open(model_dir+f\"{data_type}_model_topology.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(model_dir+f\"{data_type}_model_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model after training\n",
    "K.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Load GTEx v8 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(\n",
    "    input_dir + 'gtex_filtered_tmm_intersect_test.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(\"type\", axis=1)\n",
    "y_test = test_data[\"type\"]\n",
    "\n",
    "\n",
    "X_test = log_transform(X_test)\n",
    "X_test = convert_2d(X_test)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model beatifully\n",
    "model_json_path = model_dir+f\"{data_type}_model_topology.json\"\n",
    "trained_model = model_from_json(\n",
    "    open(model_json_path, \"r\").read()\n",
    ")\n",
    "\n",
    "# load weights into new model\n",
    "model_weights_path = model_dir+f\"{data_type}_model_weights.hdf5\"\n",
    "trained_model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions and add everything to a giant DataFrame\n",
    "y_preds = trained_model.predict_classes(\n",
    "    X_test\n",
    ")\n",
    "num_preds = len(y_preds)\n",
    "\n",
    "classes = test_data[\"type\"].unique()\n",
    "num_classes = len(classes)\n",
    "\n",
    "y_preds_onehot = np.zeros([num_preds, num_classes])\n",
    "y_preds_onehot[np.arange(num_preds), y_preds] = 1\n",
    "\n",
    "y_preds_labels = lb.inverse_transform(y_preds_onehot)\n",
    "\n",
    "print(\n",
    "    f\"macro-average F1 : {f1_score(y_test, y_preds_labels, average='macro')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapenv",
   "language": "python",
   "name": "shapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}